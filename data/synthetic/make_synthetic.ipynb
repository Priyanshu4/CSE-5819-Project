{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"synthetic_mid_10k\" \n",
    "DATASET_COMMENT = \"Medium difficult synthetic dataset with 10k users and 3 fraud groups of size 100 (20 products), 50 (30 products), and 20 (10 products). There is also some noise.\"\n",
    "n_users = 10000   # Number of users\n",
    "n_items = 100     # Number of items\n",
    "n_ratings = 30000 # Number of ratings\n",
    "fraud_group_sizes = [(100, 20), (50, 30), (20, 10)]\n",
    "additive_noise = 1\n",
    "subtractive_noise = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_synthetic_dataset(n_users: int, n_items: int, n_reviews: int, fraud_group_sizes: list):\n",
    "    \"\"\" Creates the graph_u2p and labels for a synthetic dataset. \n",
    "        In the synthetic dataset generated, every fraudster will review every target item for their group.\n",
    "        However, they may also have reviewed other items as well.\n",
    "        This function can be used in combination with add_noise to add additional noise to the dataset.\n",
    "    \n",
    "    Args:\n",
    "        n_users: Number of users in the dataset.\n",
    "        n_items: Number of items in the dataset.\n",
    "        n_reviews: Number of non-fraudulent reviews in the dataset.\n",
    "        fraud_group_sizes: List of tuples. Each tuple is in format (n_users_in_group, n_items_targeted)\n",
    "\n",
    "    Returns:\n",
    "        graph_u2i: Sparse matrix of shape (n_users, n_items) with 1s in the positions where a user has reviewed an item.\n",
    "        labels: array of labels for each user in the dataset. 1 if the user is fraudulent, 0 otherwise.\n",
    "    \"\"\"\n",
    "    # Initialize empty graph_u2i and labels\n",
    "    graph_u2i = csr_matrix((n_users, n_items), dtype=np.int8)\n",
    "    labels = np.zeros(n_users, dtype=np.int8)\n",
    "\n",
    "    # Generate non-fradulent reviews\n",
    "    remaining_reviews = n_reviews\n",
    "    remaining_users = n_users\n",
    "    for user in range(n_users):\n",
    "        avg_reviews_per_user = remaining_reviews / remaining_users\n",
    "        num_to_review = int(np.random.normal(loc=avg_reviews_per_user, scale=avg_reviews_per_user))\n",
    "        num_to_review = min(num_to_review, remaining_reviews, n_items)\n",
    "        num_to_review = max(num_to_review, 1)\n",
    "        \n",
    "        # Fill the graph_u2i matrix with 1s\n",
    "        items = np.random.choice(n_items, num_to_review, replace=False)\n",
    "        graph_u2i[user, items] = 1\n",
    "        \n",
    "        # Update remaining reviews and users\n",
    "        remaining_reviews -= num_to_review\n",
    "        remaining_users -= 1\n",
    "\n",
    "    # Generate fraudulent reviews\n",
    "    # For each fraudulent group, randomly choose that many users to be fraudulent\n",
    "    # For each fraudulent group, we will choose some number of items to target\n",
    "    # All users in the fraudulent group will review all items in the group\n",
    "    for i, group_info in enumerate(fraud_group_sizes):\n",
    "        group_size, num_items_targeted = group_info\n",
    "        users = np.random.choice(n_users, group_size, replace=False)\n",
    "        items = np.random.choice(n_items, num_items_targeted, replace=False)\n",
    "        graph_u2i[users[:, None], items] = 1\n",
    "        labels[users] = i + 1\n",
    "    \n",
    "    return graph_u2i, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_to_fraudsters(graph_u2i, labels, additive_noise, subtractive_noise):\n",
    "    \"\"\" For each fraudster, this randomly adds and removes edges from the graph_u2i matrix.\n",
    "    \n",
    "    Args:\n",
    "        graph_u2i: Sparse matrix of shape (n_users, n_items) with 1s in the positions where a user has reviewed an item.\n",
    "        labels: array of labels for each user in the dataset. 1 if the user is fraudulent, 0 otherwise.\n",
    "        additive_noise: number of edges to add to each fraudster\n",
    "        subtractive_noise: number of edges to remove from each fraudster\n",
    "    \"\"\"\n",
    "\n",
    "    # For each fraudster, add and remove edges\n",
    "    fraudsters = np.where(labels > 0)[0]\n",
    "    for fraudster in fraudsters:\n",
    "        dense_row = graph_u2i[fraudster].toarray()[0]\n",
    "\n",
    "        # Add edges     \n",
    "        items_to_add = np.random.choice(np.where(dense_row == 0)[0], additive_noise, replace=False)\n",
    "        graph_u2i[fraudster, items_to_add] = 1\n",
    "\n",
    "        # Remove edges\n",
    "        items_to_remove = np.random.choice(np.where(dense_row == 1)[0], subtractive_noise, replace=False)\n",
    "        graph_u2i[fraudster, items_to_remove] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agpri\\miniconda3\\envs\\fake-review-detection-env\\Lib\\site-packages\\scipy\\sparse\\_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m graph_u2i, labels \u001b[38;5;241m=\u001b[39m build_synthetic_dataset(n_users, n_items, n_ratings, fraud_group_sizes)\n\u001b[0;32m      2\u001b[0m add_noise_to_fraudsters(graph_u2i, labels, additive_noise, subtractive_noise)\n",
      "Cell \u001b[1;32mIn[3], line 43\u001b[0m, in \u001b[0;36mbuild_synthetic_dataset\u001b[1;34m(n_users, n_items, n_reviews, fraud_group_sizes)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Generate fraudulent reviews\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# For each fraudulent group, randomly choose that many users to be fraudulent\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# For each fraudulent group, we will choose some number of items to target\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# All users in the fraudulent group will review all items in the group\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group_info \u001b[38;5;129;01min\u001b[39;00m fraud_group_sizes:\n\u001b[1;32m---> 43\u001b[0m     group_size, num_items_targeted \u001b[38;5;241m=\u001b[39m group_info\n\u001b[0;32m     44\u001b[0m     users \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(n_users, group_size, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m     items \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(n_items, num_items_targeted, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "graph_u2i, labels = build_synthetic_dataset(n_users, n_items, n_ratings, fraud_group_sizes)\n",
    "add_noise_to_fraudsters(graph_u2i, labels, additive_noise, subtractive_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folder if it does not exist\n",
    "Path(DATASET_NAME).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Write graph_u2i as pickle\n",
    "with open(Path(DATASET_NAME) / 'graph_u2i.pkl', 'wb') as f:\n",
    "    pickle.dump(graph_u2i, f, protocol=4)\n",
    "\n",
    "# Write labels as pickle\n",
    "with open(Path(DATASET_NAME) / 'labels.pkl', 'wb') as f:\n",
    "    pickle.dump(labels, f, protocol=4)\n",
    "\n",
    "\n",
    "# Create a dictionary with the dataset information\n",
    "dataset_info = {\n",
    "    \"dataset_name\": DATASET_NAME,\n",
    "    \"dataset_comment\": DATASET_COMMENT,\n",
    "    \"n_users\": n_users,\n",
    "    \"n_items\": n_items,\n",
    "    \"n_legitimate_ratings\": n_ratings,\n",
    "    \"fraud_group_sizes\": fraud_group_sizes,\n",
    "    \"additive_noise\": additive_noise,\n",
    "    \"subtractive_noise\": subtractive_noise\n",
    "}\n",
    "\n",
    "# Write the dataset information to description.json\n",
    "with open(Path(DATASET_NAME) / 'description.json', 'w') as f:\n",
    "    json.dump(dataset_info, f, indent = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
