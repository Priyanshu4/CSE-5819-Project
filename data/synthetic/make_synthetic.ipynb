{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"synthetic_easy_1000\" \n",
    "DATASET_COMMENT = \"Easy synthetic dataset with one group of 1000 fraudsters\"\n",
    "n_users = 10000   # Number of users\n",
    "n_items = 100     # Number of items\n",
    "n_ratings = 30000 # Number of ratings\n",
    "fraud_group_sizes = [(1000, 10)]\n",
    "additive_noise = 0\n",
    "subtractive_noise = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_synthetic_dataset(n_users: int, n_items: int, n_reviews: int, fraud_group_sizes: list):\n",
    "    \"\"\" Creates the graph_u2p and labels for a synthetic dataset. \n",
    "        In the synthetic dataset generated, every fraudster will review every target item for their group.\n",
    "        However, they may also have reviewed other items as well.\n",
    "        This function can be used in combination with add_noise to add additional noise to the dataset.\n",
    "    \n",
    "    Args:\n",
    "        n_users: Number of users in the dataset.\n",
    "        n_items: Number of items in the dataset.\n",
    "        n_reviews: Number of non-fraudulent reviews in the dataset.\n",
    "        fraud_group_sizes: List of tuples. Each tuple is in format (n_users_in_group, n_items_targeted)\n",
    "\n",
    "    Returns:\n",
    "        graph_u2i: Sparse matrix of shape (n_users, n_items) with 1s in the positions where a user has reviewed an item.\n",
    "        labels: array of labels for each user in the dataset. 1 if the user is fraudulent, 0 otherwise.\n",
    "    \"\"\"\n",
    "    # Initialize empty graph_u2i and labels\n",
    "    graph_u2i = csr_matrix((n_users, n_items), dtype=np.int8)\n",
    "    labels = np.zeros(n_users, dtype=np.int8)\n",
    "\n",
    "    # Generate non-fradulent reviews\n",
    "    remaining_reviews = n_reviews\n",
    "    remaining_users = n_users\n",
    "    for user in range(n_users):\n",
    "        avg_reviews_per_user = remaining_reviews / remaining_users\n",
    "        num_to_review = int(np.random.normal(loc=avg_reviews_per_user, scale=avg_reviews_per_user/2))\n",
    "        num_to_review = min(num_to_review, remaining_reviews, n_items)\n",
    "        num_to_review = max(num_to_review, 1)\n",
    "        \n",
    "        # Fill the graph_u2i matrix with 1s\n",
    "        items = np.random.choice(n_items, num_to_review, replace=False)\n",
    "        graph_u2i[user, items] = 1\n",
    "        \n",
    "        # Update remaining reviews and users\n",
    "        remaining_reviews -= num_to_review\n",
    "        remaining_users -= 1\n",
    "\n",
    "    # Generate fraudulent reviews\n",
    "    # For each fraudulent group, randomly choose that many users to be fraudulent\n",
    "    # For each fraudulent group, we will choose some number of items to target\n",
    "    # All users in the fraudulent group will review all items in the group\n",
    "    for group_size, num_items_targeted in fraud_group_sizes:\n",
    "        users = np.random.choice(n_users, group_size, replace=False)\n",
    "        items = np.random.choice(n_items, num_items_targeted, replace=False)\n",
    "        graph_u2i[users[:, None], items] = 1\n",
    "        labels[users] = 1\n",
    "    \n",
    "    return graph_u2i, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_to_fraudsters(graph_u2i, labels, additive_noise, subtractive_noise):\n",
    "    \"\"\" For each fraudster, this randomly adds and removes edges from the graph_u2i matrix.\n",
    "    \n",
    "    Args:\n",
    "        graph_u2i: Sparse matrix of shape (n_users, n_items) with 1s in the positions where a user has reviewed an item.\n",
    "        labels: array of labels for each user in the dataset. 1 if the user is fraudulent, 0 otherwise.\n",
    "        additive_noise: number of edges to add to each fraudster\n",
    "        subtractive_noise: number of edges to remove from each fraudster\n",
    "    \"\"\"\n",
    "\n",
    "    # For each fraudster, add and remove edges\n",
    "    fraudsters = np.where(labels == 1)[0]\n",
    "    for fraudster in fraudsters:\n",
    "        # Add edges\n",
    "        \n",
    "        items_to_add = np.random.choice(np.where(graph_u2i[fraudster].toarray() == 0)[0], additive_noise, replace=False)\n",
    "        graph_u2i[fraudster, items_to_add] = 1\n",
    "\n",
    "        # Remove edges\n",
    "        items_to_remove = np.random.choice(np.where(graph_u2i[fraudster].toarray() == 1)[0], subtractive_noise, replace=False)\n",
    "        graph_u2i[fraudster, items_to_remove] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agpri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "graph_u2i, labels = build_synthetic_dataset(n_users, n_items, n_ratings, fraud_group_sizes)\n",
    "add_noise_to_fraudsters(graph_u2i, labels, additive_noise, subtractive_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folder if it does not exist\n",
    "Path(DATASET_NAME).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Write graph_u2i as pickle\n",
    "with open(Path(DATASET_NAME) / 'graph_u2i.pkl', 'wb') as f:\n",
    "    pickle.dump(graph_u2i, f, protocol=4)\n",
    "\n",
    "# Write labels as pickle\n",
    "with open(Path(DATASET_NAME) / 'labels.pkl', 'wb') as f:\n",
    "    pickle.dump(labels, f, protocol=4)\n",
    "\n",
    "\n",
    "# Create a dictionary with the dataset information\n",
    "dataset_info = {\n",
    "    \"dataset_name\": DATASET_NAME,\n",
    "    \"dataset_comment\": DATASET_COMMENT,\n",
    "    \"n_users\": n_users,\n",
    "    \"n_items\": n_items,\n",
    "    \"n_legitimate_ratings\": n_ratings,\n",
    "    \"fraud_group_sizes\": fraud_group_sizes\n",
    "}\n",
    "\n",
    "# Write the dataset information to description.json\n",
    "with open(Path(DATASET_NAME) / 'description.json', 'w') as f:\n",
    "    json.dump(dataset_info, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
